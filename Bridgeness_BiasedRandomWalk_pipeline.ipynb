{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import bridgeness\n",
    "from numpy.random import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FN = \"lfr2k_nodes.csv\"\n",
    "FN = \"graph.txt.csv\"\n",
    "data = pd.read_csv(\"graph.txt.csv\", delimiter = \" \")\n",
    "#data = pd.read_csv(\"lfr2_edges.csv\", delimiter = \"\\t\")\n",
    "#data = pd.read_csv(\"graph2-200nodi-twomoons.txt\", header=None, delim_whitespace=True, skipinitialspace=True, usecols=[1,2])#delimiter = \"\\t\"\n",
    "#data = pd.read_csv(FN, delimiter = \"\\t\")\n",
    "#print(data)\n",
    "G = nx.Graph()\n",
    "\n",
    "for i,s in data.iterrows():\n",
    "    u = s[0]\n",
    "    v = s[1]\n",
    "\n",
    "    G.add_edge(u,v)\n",
    "\n",
    "#print(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bri = bridgeness.bridgeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#e_bri = bridgeness.edge_bridgeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bet = bridgeness.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "net -> adj matr\n",
    "bri+adj -> tran matr\n",
    "    in> vec bri, adj mat\n",
    "    out > tran matr\n",
    "    \n",
    "    matr diagonal di vec bri (qualities)\n",
    "    _tmp = diag*adjmat (prod matriciale)\n",
    "    norm = diag(sum(temp, sulle righe))\n",
    "    T = _tmp*(norm^-1) matr trans normalizzata\n",
    "\n",
    "\n",
    "#1: closed form -> matr inv\n",
    "    in>  tran_matr + parm mu + labels (y*k)\n",
    "    out> N*k\n",
    "    \n",
    "    alpha = 2/(2+mu)\n",
    "    op = ( (1-alpha) * eye(N)) / ((eye(N) - alpha * tran_matr))\n",
    "\"\"\"\n",
    "\n",
    "phi = 100\n",
    "phi = 3 ###temp\n",
    "mu = 2.0\n",
    "mu = 0.01 ##temp\n",
    "lab0 = 95\n",
    "lab1 = 190\n",
    "\n",
    "adj = nx.to_numpy_matrix(G)\n",
    "quality = (1 / np.exp( np.multiply(bri.values(), phi )))\n",
    "diag = np.diagflat(quality) #k: v = node, bridgeness\n",
    "_tmp = np.matmul(diag, adj)\n",
    "_tmp_sum_on_rows = np.sum(_tmp, axis=0)\n",
    "_tmp_sum_on_rows_recip = np.reciprocal(_tmp_sum_on_rows)\n",
    "norm = np.diagflat( _tmp_sum_on_rows_recip )\n",
    "\n",
    "T = np.matmul( _tmp, norm )\n",
    "\n",
    "#######\n",
    "\n",
    "num_nodes = len(G.nodes())\n",
    "alpha = 2.0/(2.0 + mu)\n",
    "prob_comm = T \n",
    "\n",
    "\n",
    "labels = np.zeros( (num_nodes, 2) )\n",
    "labels[lab0,0] = 1\n",
    "labels[lab1,1] = 1\n",
    "\n",
    "op1 = (1-alpha) * np.eye(num_nodes) \n",
    "op2 = ( np.eye(num_nodes) - ( alpha * T))\n",
    "op = np.dot(op1, op2.I)\n",
    "\n",
    "probs = np.dot(op, labels)\n",
    "\n",
    "#bri.items()\n",
    "#reload(bridgeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(adj[0])\n",
    "#print(_tmp[0])\n",
    "#print(np.sum(adj, axis=0))\n",
    "#print(_tmp_sum_on_rows)\n",
    "#print(sum(_tmp[:,0]))\n",
    "#print(norm)\n",
    "#print(norm_recip)\n",
    "#print( sum(T[:,2] ))\n",
    "#print(T)\n",
    "#print( (1-alpha) * np.eye(num_nodes) )\n",
    "#print( np.eye(num_nodes) - ( alpha * T) )\n",
    "#print(op)\n",
    "#p0 = probs[:,0]\n",
    "#p1 = probs[:,1]\n",
    "#print( probs[p0 >p1] )\n",
    "#print(probs)\n",
    "pd.DataFrame.to_csv(pd.DataFrame(probs), 'probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.995\n",
      "At step 10000, diff 0.0054439600\n",
      "At step 20000, diff 0.0013877350\n",
      "At step 30000, diff 0.0006283689\n",
      "At step 40000, diff 0.0003838462\n",
      "At step 50000, diff 0.0002392304\n",
      "At step 60000, diff 0.0001789167\n",
      "At step 70000, diff 0.0001342518\n",
      "At step 80000, diff 0.0000900241\n",
      "At step 90000, diff 0.0000727296\n",
      "At step 100000, diff 0.0000634102\n",
      "At step 110000, diff 0.0000456937\n",
      "At step 120000, diff 0.0000412819\n",
      "At step 130000, diff 0.0000383707\n",
      "At step 140000, diff 0.0000290258\n",
      "At step 150000, diff 0.0000260314\n",
      "At step 160000, diff 0.0000284462\n",
      "At step 170000, diff 0.0000208914\n",
      "At step 180000, diff 0.0000184643\n",
      "At step 190000, diff 0.0000174299\n",
      "At step 200000, diff 0.0000146022\n",
      "At step 210000, diff 0.0000122014\n",
      "At step 220000, diff 0.0000118516\n",
      "At step 230000, diff 0.0000104514\n",
      "At step 240000, diff 0.0000114272\n",
      "At step 250000, diff 0.0000089374\n",
      "At step 260000, diff 0.0000092441\n",
      "At step 270000, diff 0.0000093526\n",
      "At step 280000, diff 0.0000069613\n",
      "At step 290000, diff 0.0000074423\n",
      "At step 300000, diff 0.0000077880\n",
      "At step 310000, diff 0.0000063169\n",
      "At step 320000, diff 0.0000061804\n",
      "At step 330000, diff 0.0000055371\n",
      "At step 340000, diff 0.0000050796\n",
      "At step 350000, diff 0.0000060305\n",
      "At step 360000, diff 0.0000045106\n",
      "At step 370000, diff 0.0000042803\n",
      "At step 380000, diff 0.0000039101\n",
      "At step 390000, diff 0.0000037743\n",
      "At step 400000, diff 0.0000041249\n",
      "At step 410000, diff 0.0000036123\n",
      "At step 420000, diff 0.0000036747\n",
      "At step 430000, diff 0.0000036639\n",
      "At step 440000, diff 0.0000030884\n",
      "At step 450000, diff 0.0000026718\n",
      "At step 460000, diff 0.0000030089\n",
      "At step 470000, diff 0.0000030633\n",
      "At step 480000, diff 0.0000025628\n",
      "At step 490000, diff 0.0000022740\n",
      "At step 500000, diff 0.0000024309\n",
      "At step 510000, diff 0.0000023008\n",
      "At step 520000, diff 0.0000024175\n",
      "At step 530000, diff 0.0000023432\n",
      "At step 540000, diff 0.0000019867\n",
      "At step 550000, diff 0.0000021039\n",
      "At step 560000, diff 0.0000019388\n",
      "At step 570000, diff 0.0000021752\n",
      "At step 580000, diff 0.0000018091\n",
      "At step 590000, diff 0.0000016743\n",
      "At step 600000, diff 0.0000016579\n",
      "At step 610000, diff 0.0000016714\n",
      "At step 620000, diff 0.0000016412\n",
      "At step 630000, diff 0.0000015456\n",
      "At step 640000, diff 0.0000015470\n",
      "At step 650000, diff 0.0000013378\n",
      "At step 660000, diff 0.0000014732\n",
      "At step 670000, diff 0.0000014123\n",
      "At step 680000, diff 0.0000012721\n",
      "At step 690000, diff 0.0000011830\n",
      "At step 700000, diff 0.0000011767\n",
      "At step 710000, diff 0.0000011849\n",
      "At step 720000, diff 0.0000011430\n",
      "At step 730000, diff 0.0000012350\n",
      "At step 740000, diff 0.0000010901\n",
      "At step 750000, diff 0.0000011603\n",
      "At step 760000, diff 0.0000010464\n",
      "At step 770000, diff 0.0000010030\n",
      "At step 780000, diff 0.0000009012\n",
      "Converged at <0.0000010000\n",
      "At step 10000, diff 0.0057570000\n",
      "At step 20000, diff 0.0015488450\n",
      "At step 30000, diff 0.0006547867\n",
      "At step 40000, diff 0.0003967000\n",
      "At step 50000, diff 0.0002302552\n",
      "At step 60000, diff 0.0001684211\n",
      "At step 70000, diff 0.0001123784\n",
      "At step 80000, diff 0.0000855356\n",
      "At step 90000, diff 0.0000771005\n",
      "At step 100000, diff 0.0000580670\n",
      "At step 110000, diff 0.0000490826\n",
      "At step 120000, diff 0.0000455361\n",
      "At step 130000, diff 0.0000396692\n",
      "At step 140000, diff 0.0000277530\n",
      "At step 150000, diff 0.0000271255\n",
      "At step 160000, diff 0.0000282000\n",
      "At step 170000, diff 0.0000218909\n",
      "At step 180000, diff 0.0000175052\n",
      "At step 190000, diff 0.0000171768\n",
      "At step 200000, diff 0.0000164593\n",
      "At step 210000, diff 0.0000131218\n",
      "At step 220000, diff 0.0000141840\n",
      "At step 230000, diff 0.0000113620\n",
      "At step 240000, diff 0.0000103560\n",
      "At step 250000, diff 0.0000090388\n",
      "At step 260000, diff 0.0000093531\n",
      "At step 270000, diff 0.0000080415\n",
      "At step 280000, diff 0.0000076595\n",
      "At step 290000, diff 0.0000073446\n",
      "At step 300000, diff 0.0000069885\n",
      "At step 310000, diff 0.0000064993\n",
      "At step 320000, diff 0.0000068823\n",
      "At step 330000, diff 0.0000054846\n",
      "At step 340000, diff 0.0000049472\n",
      "At step 350000, diff 0.0000045746\n",
      "At step 360000, diff 0.0000045892\n",
      "At step 370000, diff 0.0000048364\n",
      "At step 380000, diff 0.0000039087\n",
      "At step 390000, diff 0.0000041209\n",
      "At step 400000, diff 0.0000038977\n",
      "At step 410000, diff 0.0000037542\n",
      "At step 420000, diff 0.0000040106\n",
      "At step 430000, diff 0.0000028749\n",
      "At step 440000, diff 0.0000034520\n",
      "At step 450000, diff 0.0000027618\n",
      "At step 460000, diff 0.0000029491\n",
      "At step 470000, diff 0.0000026530\n",
      "At step 480000, diff 0.0000024882\n",
      "At step 490000, diff 0.0000023952\n",
      "At step 500000, diff 0.0000023478\n",
      "At step 510000, diff 0.0000022379\n",
      "At step 520000, diff 0.0000022889\n",
      "At step 530000, diff 0.0000021625\n",
      "At step 540000, diff 0.0000020618\n",
      "At step 550000, diff 0.0000019729\n",
      "At step 560000, diff 0.0000020026\n",
      "At step 570000, diff 0.0000020160\n",
      "At step 580000, diff 0.0000018722\n",
      "At step 590000, diff 0.0000017240\n",
      "At step 600000, diff 0.0000016520\n",
      "At step 610000, diff 0.0000014524\n",
      "At step 620000, diff 0.0000016231\n",
      "At step 630000, diff 0.0000014016\n",
      "At step 640000, diff 0.0000013948\n",
      "At step 650000, diff 0.0000014922\n",
      "At step 660000, diff 0.0000014497\n",
      "At step 670000, diff 0.0000013082\n",
      "At step 680000, diff 0.0000012008\n",
      "At step 690000, diff 0.0000011927\n",
      "At step 700000, diff 0.0000014429\n",
      "At step 710000, diff 0.0000012208\n",
      "At step 720000, diff 0.0000011578\n",
      "At step 730000, diff 0.0000010653\n",
      "At step 740000, diff 0.0000010560\n",
      "At step 750000, diff 0.0000010675\n",
      "At step 760000, diff 0.0000011492\n",
      "At step 770000, diff 0.0000011285\n",
      "At step 780000, diff 0.0000009149\n",
      "Converged at <0.0000010000\n"
     ]
    }
   ],
   "source": [
    "#2 RW\n",
    "\n",
    "#start from lab0(s), lab1(s)\n",
    "\n",
    "\n",
    "steps = 1000000 #max steps\n",
    "convcheckfreq = 10000 #check if converged every N steps\n",
    "conv_thr = 1e-06\n",
    "\n",
    "\n",
    "n0 = lab0\n",
    "#n0 = 188\n",
    "n1 = lab1\n",
    "\n",
    "labels=[n0,n1]\n",
    "\n",
    "#visit probability vec\n",
    "rw_visits = np.zeros( (num_nodes, 2) )\n",
    "last_rw_visits = np.copy(rw_visits)\n",
    "\n",
    "nodes = range(num_nodes)\n",
    "\n",
    "print(\"Alpha = %.3f\" %(alpha))\n",
    "\n",
    "#COMM0\n",
    "for s0 in xrange(1,steps+1):\n",
    "\n",
    "    #start from\n",
    "    #go back to labeled node? prob = 1-alpha; prob to trans = alpha\n",
    "    if (uniform() < alpha): #\n",
    "        trans_probs = T[:,n0].view(np.ndarray).flatten() \n",
    "        trans_to = int( choice(nodes, 1, p = trans_probs) )\n",
    "        n0 = trans_to\n",
    "    else:\n",
    "        n0 = lab0\n",
    "\n",
    "    rw_visits[n0,0] += 1\n",
    "    \n",
    "    if (s0 % convcheckfreq == 0):\n",
    "        diff_rw_visits = ((rw_visits[:,0]/s0 - last_rw_visits[:,0]/s0)**2).sum()\n",
    "        print(\"At step %d, diff %.10f\" %(s0, diff_rw_visits) )\n",
    "        if ((diff_rw_visits) < conv_thr):# and np.all(rw_visits != last_rw_visits)):\n",
    "            print(\"Converged at <%.10f\" % conv_thr)\n",
    "            break\n",
    "        last_rw_visits = np.copy(rw_visits)\n",
    "\n",
    "#print(\"At step %d, last diff %.5f\" % ( s0, diff_rw_visits) )\n",
    "\n",
    "#COMM1\n",
    "for s1 in xrange(1,steps+1):\n",
    "\n",
    "    #start from\n",
    "    #go back to labeled node? prob = 1-alpha; prob to trans = alpha\n",
    "    if (uniform() < alpha): #\n",
    "        #print(\"Transaction.\")\n",
    "        #probs to trans to node\n",
    "        trans_probs = T[:,n1].view(np.ndarray).flatten() \n",
    "        trans_to = int( choice(nodes, 1, p = trans_probs) )\n",
    "        #print(trans_to)\n",
    "        n1 = trans_to\n",
    "    else:\n",
    "        #print(\"Go back.\")\n",
    "        n1 = lab1\n",
    "\n",
    "    rw_visits[n1,1] += 1\n",
    "    \n",
    "    if (s1 % convcheckfreq == 0):\n",
    "        diff_rw_visits = ((rw_visits[:,1]/s1 - last_rw_visits[:,1]/s1)**2).sum()\n",
    "        print(\"At step %d, diff %.10f\" %(s1, diff_rw_visits) )\n",
    "        if ((diff_rw_visits) < conv_thr):# and np.all(rw_visits != last_rw_visits)):\n",
    "            print(\"Converged at <%.10f\" % conv_thr)\n",
    "            break\n",
    "        last_rw_visits = np.copy(rw_visits)\n",
    "\n",
    "#print(\"At step %d, last diff %.5f\" % ( s1, diff_rw_visits) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rw_visits[:,0]/steps - last_rw_visits[:,0]/steps\n",
    "comm_cf = ( (probs[:,0]) > (probs[:,1]) )\n",
    "comm_rw = ( (rw_visits[:,0]/s0) > (rw_visits[:,1]/s1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(comm_cf, comm_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.0079    , 0.00689231, 0.00665513, 0.00897051, 0.00608974,\n",
      "       0.00386795, 0.0049141 , 0.00649487, 0.00656282, 0.00763718,\n",
      "       0.0059141 , 0.00696282, 0.00613718, 0.00837179, 0.00930769,\n",
      "       0.00718205, 0.00893462, 0.00414231, 0.00529744, 0.00572179,\n",
      "       0.00986923, 0.00657949, 0.00641282, 0.00706795, 0.00822179,\n",
      "       0.00710385, 0.00445769, 0.0071359 , 0.00559487, 0.00695385,\n",
      "       0.00604487, 0.00654615, 0.00649744, 0.0058859 , 0.00701282,\n",
      "       0.0056859 , 0.00544744, 0.00661026, 0.00606538, 0.00561538,\n",
      "       0.00527051, 0.00869744, 0.00891026, 0.00733333, 0.00644359,\n",
      "       0.00593846, 0.00937051, 0.00618846, 0.00513333, 0.0077    ,\n",
      "       0.00687692, 0.00598333, 0.00796923, 0.00678077, 0.00809872,\n",
      "       0.0087641 , 0.00780641, 0.00501538, 0.00564872, 0.00837564,\n",
      "       0.00548205, 0.00632051, 0.00609744, 0.00478718, 0.00534615,\n",
      "       0.00416923, 0.01087949, 0.00638718, 0.00476282, 0.00584103,\n",
      "       0.00758077, 0.00655   , 0.00658333, 0.00755513, 0.00771282,\n",
      "       0.00487308, 0.00924744, 0.0067    , 0.00615769, 0.00603718,\n",
      "       0.00729103, 0.00681154, 0.00607051, 0.00674231, 0.00584744,\n",
      "       0.00555769, 0.00577692, 0.00668974, 0.00744103, 0.00554231,\n",
      "       0.00694103, 0.00596026, 0.00514103, 0.00736154, 0.00697051,\n",
      "       0.01338205, 0.00634615, 0.00855641, 0.00530513, 0.01022564,\n",
      "       0.00308077, 0.00317692, 0.00292949, 0.00362949, 0.00306026,\n",
      "       0.00223718, 0.00313205, 0.00290641, 0.00296538, 0.00286026,\n",
      "       0.00361026, 0.00365128, 0.00298333, 0.00313718, 0.00367308,\n",
      "       0.00417308, 0.00354231, 0.00274615, 0.00340641, 0.00290641,\n",
      "       0.00400128, 0.00324872, 0.00267692, 0.00296923, 0.00303846,\n",
      "       0.00289744, 0.00294231, 0.00313077, 0.00275769, 0.0028359 ,\n",
      "       0.00341795, 0.00281282, 0.00277436, 0.00360385, 0.00418077,\n",
      "       0.00315128, 0.00303205, 0.00299487, 0.00298718, 0.00333718,\n",
      "       0.00320385, 0.00356923, 0.00370769, 0.00307051, 0.00275513,\n",
      "       0.00331026, 0.00367564, 0.00286282, 0.00325513, 0.0034    ,\n",
      "       0.00411795, 0.00294359, 0.00299231, 0.00299487, 0.00337308,\n",
      "       0.00345385, 0.00296667, 0.00331026, 0.00325385, 0.00358205,\n",
      "       0.00324359, 0.00304872, 0.00269487, 0.00313333, 0.00270256,\n",
      "       0.00269487, 0.00433718, 0.00319231, 0.00310897, 0.00310128,\n",
      "       0.00280385, 0.00286795, 0.00375769, 0.00463974, 0.00310128,\n",
      "       0.0029359 , 0.00392051, 0.00293974, 0.00383718, 0.00286667,\n",
      "       0.00326282, 0.00317436, 0.00319744, 0.00383077, 0.00273462,\n",
      "       0.00339487, 0.00373333, 0.00288205, 0.00321026, 0.0033641 ,\n",
      "       0.00403077, 0.00289744, 0.00294231, 0.00291667, 0.00318718,\n",
      "       0.00329615, 0.0036141 , 0.00331154, 0.00304487, 0.00454744]), array([0.0030859 , 0.00304487, 0.00289615, 0.00385256, 0.00415128,\n",
      "       0.00231282, 0.00318077, 0.00278974, 0.00314744, 0.00294487,\n",
      "       0.00377051, 0.00317436, 0.00271667, 0.00324872, 0.00383718,\n",
      "       0.00487051, 0.00362308, 0.00275641, 0.00247436, 0.00361538,\n",
      "       0.00404615, 0.00288974, 0.00296538, 0.00307692, 0.00333333,\n",
      "       0.00290128, 0.00304231, 0.00327308, 0.00305769, 0.00301667,\n",
      "       0.00385769, 0.00288974, 0.00293846, 0.00384231, 0.00461795,\n",
      "       0.00357436, 0.00340385, 0.00273205, 0.00337179, 0.00392308,\n",
      "       0.00400769, 0.00369487, 0.00357692, 0.00321923, 0.00312179,\n",
      "       0.00373333, 0.00370513, 0.00318718, 0.00346667, 0.00331538,\n",
      "       0.00451795, 0.00335   , 0.00314615, 0.00310641, 0.00353333,\n",
      "       0.00353974, 0.00312179, 0.00338462, 0.00348205, 0.00347179,\n",
      "       0.00351154, 0.00288462, 0.00297051, 0.00320128, 0.00248077,\n",
      "       0.00274487, 0.00457949, 0.00289231, 0.00321538, 0.00366538,\n",
      "       0.00298846, 0.0028141 , 0.00414487, 0.00500769, 0.00308846,\n",
      "       0.00330897, 0.00392692, 0.00322821, 0.00419744, 0.00311795,\n",
      "       0.00324744, 0.00342821, 0.00354872, 0.00432692, 0.00298077,\n",
      "       0.00352692, 0.00385   , 0.00294744, 0.00352179, 0.00365256,\n",
      "       0.00440513, 0.00317051, 0.00313077, 0.00305641, 0.00337692,\n",
      "       0.00341282, 0.00386026, 0.00338077, 0.00348333, 0.00438974,\n",
      "       0.00511795, 0.00493205, 0.00463333, 0.00667308, 0.00743462,\n",
      "       0.00346154, 0.00678205, 0.00465897, 0.00614359, 0.00501282,\n",
      "       0.00892692, 0.00555513, 0.0046    , 0.00550256, 0.00676154,\n",
      "       0.01003205, 0.00639487, 0.00465128, 0.00521923, 0.00736154,\n",
      "       0.00673718, 0.00506667, 0.00584103, 0.00530256, 0.00551667,\n",
      "       0.00546154, 0.00516282, 0.00658718, 0.00653333, 0.0056859 ,\n",
      "       0.00840769, 0.00459615, 0.0057859 , 0.00837308, 0.00974615,\n",
      "       0.00778077, 0.00747564, 0.00465256, 0.00716154, 0.00750256,\n",
      "       0.00754103, 0.00674103, 0.00617821, 0.00606538, 0.00517949,\n",
      "       0.00812436, 0.0064141 , 0.00667179, 0.00719744, 0.00545897,\n",
      "       0.00947692, 0.00732436, 0.00521923, 0.00591923, 0.00651154,\n",
      "       0.00613846, 0.00543718, 0.00715769, 0.00794872, 0.00577051,\n",
      "       0.00801923, 0.00495   , 0.00607308, 0.00691026, 0.00422821,\n",
      "       0.00518462, 0.0074141 , 0.00493718, 0.00690897, 0.00794103,\n",
      "       0.00492564, 0.00439615, 0.00886026, 0.01095128, 0.00511795,\n",
      "       0.00549359, 0.00640769, 0.0060141 , 0.00893718, 0.00636795,\n",
      "       0.00521795, 0.00657179, 0.00764231, 0.00937436, 0.00626667,\n",
      "       0.00827692, 0.00842436, 0.00475128, 0.00646026, 0.00757564,\n",
      "       0.01489487, 0.00679744, 0.00737821, 0.00555256, 0.00675128,\n",
      "       0.00575385, 0.00869744, 0.00610385, 0.00765769, 0.00750897]))\n"
     ]
    }
   ],
   "source": [
    "#rw_visits[:,0]/s\n",
    "#sum((rw_visits[:,0]/s0+rw_visits[:,1]/s1))\n",
    "#rw_visits\n",
    "#print(np.max(rw_visits[:,0]/s0 - probs[:,0]), np.max(rw_visits[:,1]/s0 - probs[:,1]) )\n",
    "#print(probs)\n",
    "print((rw_visits[:,0]/s0, rw_visits[:,1]/s0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#comm_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
